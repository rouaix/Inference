# ─── Core inference ───────────────────────────────────────────────────────────
numpy>=1.24
gguf>=0.6
sentencepiece>=0.1.99

# ─── Tokenizer (extraction depuis GGUF + chargement BPE/UNIGRAM) ──────────────
tokenizers>=0.19          # HuggingFace tokenizers — BPE (Magistral, Mistral v3+)
protobuf>=4.0             # Requis par sentencepiece pour sentencepiece_model_pb2

# ─── UI ───────────────────────────────────────────────────────────────────────
gradio>=4.0

# ─── Hybrid bridge (p2p_bridge.py) ───────────────────────────────────────────
# Requires a compiled llama.cpp binary for your platform.
# Install with: pip install llama-cpp-python
llama-cpp-python>=0.3.0

# ─── distribution/reseau.py (à installer quand le module sera codé) ──────────
# requests>=2.31
# aiohttp>=3.9

# ─── distribution/p2p.py (à installer quand le module sera codé) ─────────────
# py-libp2p>=0.2
# cryptography>=41.0
